{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TEXT SUMMARIZATION**","metadata":{}},{"cell_type":"markdown","source":"#  **The goal of this project is to develop a text summarization system using the encoder decoder models and selecting an optimum model. Text summarization is the task of generating concise and informative summaries of longer texts, such as articles, documents, or news stories.**","metadata":{}},{"cell_type":"markdown","source":"# I have tried different model from huggingface library but BART model gave me a decent accuracy. So trained my model using Facebook/Bart","metadata":{}},{"cell_type":"markdown","source":" # Installing some necessary libraries for the project","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing some important libraries and functionalities","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom transformers import AutoTokenizer, BartForConditionalGeneration, EncoderDecoderConfig\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:25:29.474106Z","iopub.execute_input":"2023-06-22T11:25:29.474446Z","iopub.status.idle":"2023-06-22T11:25:29.501362Z","shell.execute_reply.started":"2023-06-22T11:25:29.474418Z","shell.execute_reply":"2023-06-22T11:25:29.500220Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Reading the data and spliting it into training and testing data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/text-data/data')\nX=df['article']\ny=df['highlights']","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:25:34.384156Z","iopub.execute_input":"2023-06-22T11:25:34.385063Z","iopub.status.idle":"2023-06-22T11:25:35.330362Z","shell.execute_reply.started":"2023-06-22T11:25:34.385020Z","shell.execute_reply":"2023-06-22T11:25:35.329423Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"paragraphs, para_test, summaries, summary_test = train_test_split(X,y,test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:25:37.688003Z","iopub.execute_input":"2023-06-22T11:25:37.688348Z","iopub.status.idle":"2023-06-22T11:25:37.697873Z","shell.execute_reply.started":"2023-06-22T11:25:37.688319Z","shell.execute_reply":"2023-06-22T11:25:37.696925Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"paragraphs = paragraphs.to_list()\nsummaries = summaries.to_list()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:25:37.930769Z","iopub.execute_input":"2023-06-22T11:25:37.931076Z","iopub.status.idle":"2023-06-22T11:25:37.936540Z","shell.execute_reply.started":"2023-06-22T11:25:37.931051Z","shell.execute_reply":"2023-06-22T11:25:37.935372Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"para_test = para_test.to_list()\nsummary_test = summary_test.to_list()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:25:38.633747Z","iopub.execute_input":"2023-06-22T11:25:38.634091Z","iopub.status.idle":"2023-06-22T11:25:38.639857Z","shell.execute_reply.started":"2023-06-22T11:25:38.634064Z","shell.execute_reply":"2023-06-22T11:25:38.638910Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing is not need in the big LLM model so I haven't done processing like removing stopwords, lemmetizing etc. Still I have mentioned the steps ","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\nprocessed_paragraphs = []\nprocessed_summaries = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for paragraph, summary in zip(paragraphs, summaries):\n    \n    paragraph_tokens = word_tokenize(paragraph)\n    summary_tokens = word_tokenize(summary)\n\n    processed_paragraph_tokens = [lemmatizer.lemmatize(token.lower()) for token in paragraph_tokens if token.lower() not in stop_words]\n    processed_summary_tokens = [lemmatizer.lemmatize(token.lower()) for token in summary_tokens if token.lower() not in stop_words]\n\n    processed_paragraph = ' '.join(processed_paragraph_tokens)\n    processed_summary = ' '.join(processed_summary_tokens)\n\n    processed_paragraphs.append(processed_paragraph)\n    processed_summaries.append(processed_summary)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initializing the Bart model and the tokenizer","metadata":{}},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:35:45.400657Z","iopub.execute_input":"2023-06-22T11:35:45.401018Z","iopub.status.idle":"2023-06-22T11:35:52.177905Z","shell.execute_reply.started":"2023-06-22T11:35:45.400990Z","shell.execute_reply":"2023-06-22T11:35:52.176938Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizing out training data (X and y label) as inputs and outputs","metadata":{}},{"cell_type":"code","source":"inputs = tokenizer(paragraphs, truncation=True, padding=True, max_length=512, return_tensors='pt')\noutputs = tokenizer(summaries, truncation=True, padding=True, max_length=128, return_tensors='pt')\n\ninput_ids = inputs.input_ids\nattention_mask = inputs.attention_mask\ndecoder_input_ids = outputs.input_ids\ndecoder_attention_mask = outputs.attention_mask\n\ntrain_dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, decoder_input_ids[:, :-1], decoder_attention_mask[:, :-1])\neval_dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, decoder_input_ids[:, :-1], decoder_attention_mask[:, :-1])","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:49:00.127921Z","iopub.execute_input":"2023-06-22T08:49:00.128625Z","iopub.status.idle":"2023-06-22T08:49:30.516575Z","shell.execute_reply.started":"2023-06-22T08:49:00.128589Z","shell.execute_reply":"2023-06-22T08:49:30.515597Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting some hyperparameters for our training purpose","metadata":{}},{"cell_type":"code","source":"train_batch_size = 8\nnum_train_epochs = 10\nlearning_rate = 2e-5","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:49:34.748195Z","iopub.execute_input":"2023-06-22T08:49:34.748658Z","iopub.status.idle":"2023-06-22T08:49:34.768608Z","shell.execute_reply.started":"2023-06-22T08:49:34.748619Z","shell.execute_reply":"2023-06-22T08:49:34.767659Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Necessary configurations to use the GPU while traning","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.decoder_start_token_id = tokenizer.bos_token_id\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:49:35.264875Z","iopub.execute_input":"2023-06-22T08:49:35.265357Z","iopub.status.idle":"2023-06-22T08:49:41.299862Z","shell.execute_reply.started":"2023-06-22T08:49:35.265265Z","shell.execute_reply":"2023-06-22T08:49:41.298892Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:49:44.893178Z","iopub.execute_input":"2023-06-22T08:49:44.893538Z","iopub.status.idle":"2023-06-22T08:49:44.899642Z","shell.execute_reply.started":"2023-06-22T08:49:44.893510Z","shell.execute_reply":"2023-06-22T08:49:44.898640Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This step is to load our data in batches so that the model does not overload and assigning a optimizer","metadata":{}},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\neval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=eval_batch_size)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T08:49:50.173505Z","iopub.execute_input":"2023-06-22T08:49:50.173875Z","iopub.status.idle":"2023-06-22T08:49:50.181799Z","shell.execute_reply.started":"2023-06-22T08:49:50.173845Z","shell.execute_reply":"2023-06-22T08:49:50.180707Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here the training begins","metadata":{}},{"cell_type":"code","source":"for epoch in range(num_train_epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        input_ids, attention_mask, decoder_input_ids, decoder_attention_mask = batch\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask, return_dict=True)\n        \n        optimizer.zero_grad()\n        optimizer.step()\n\n    print(\"Epoch\",epoch+1)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:26:59.395745Z","iopub.execute_input":"2023-06-22T11:26:59.396094Z","iopub.status.idle":"2023-06-22T11:26:59.403079Z","shell.execute_reply.started":"2023-06-22T11:26:59.396066Z","shell.execute_reply":"2023-06-22T11:26:59.402155Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1\nEpoch 2\nEpoch 3\nEpoch 4\nEpoch 5\nEpoch 6\nEpoch 7\nEpoch 8\nEpoch 9\nEpoch 10\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the model for future inferencing","metadata":{}},{"cell_type":"code","source":"model.save_pretrained('bart_model')\ntokenizer.save_pretrained('bart_tokenizer')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained(\"/kaggle/input/text-data/bart_model\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/text-data/bart_tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:27:19.495165Z","iopub.execute_input":"2023-06-22T11:27:19.495749Z","iopub.status.idle":"2023-06-22T11:27:42.464285Z","shell.execute_reply.started":"2023-06-22T11:27:19.495696Z","shell.execute_reply":"2023-06-22T11:27:42.463522Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:35:58.151679Z","iopub.execute_input":"2023-06-22T11:35:58.152029Z","iopub.status.idle":"2023-06-22T11:35:58.579098Z","shell.execute_reply.started":"2023-06-22T11:35:58.152001Z","shell.execute_reply":"2023-06-22T11:35:58.578044Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartEncoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x BartDecoderLayer(\n          (self_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:36:05.478604Z","iopub.execute_input":"2023-06-22T11:36:05.479041Z","iopub.status.idle":"2023-06-22T11:36:05.484052Z","shell.execute_reply.started":"2023-06-22T11:36:05.479008Z","shell.execute_reply":"2023-06-22T11:36:05.483047Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Just performing some inferences using some examples of training data","metadata":{}},{"cell_type":"code","source":"paragraph = (paragraphs[2])","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:32:11.771811Z","iopub.execute_input":"2023-06-22T11:32:11.772152Z","iopub.status.idle":"2023-06-22T11:32:11.776451Z","shell.execute_reply.started":"2023-06-22T11:32:11.772124Z","shell.execute_reply":"2023-06-22T11:32:11.775326Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"paragraph","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:32:11.971552Z","iopub.execute_input":"2023-06-22T11:32:11.971902Z","iopub.status.idle":"2023-06-22T11:32:11.978061Z","shell.execute_reply.started":"2023-06-22T11:32:11.971874Z","shell.execute_reply":"2023-06-22T11:32:11.976987Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'(CNN) -- Nineteen political prisoners were released by the government of Myanmar over the weekend, the human rights group Amnesty International reported Tuesday. Protesters demand democracy for Myanmar at a demonstration in New Delhi, India earlier this month. Among those released was Ma Khin Khin Leh, who was serving a life sentence because her husband, a student activist, had helped plan a protest demonstration in Bago in July 1999, according to Amnesty International USA\\'s Web blog . Authorities prevented the demonstration from taking place, but took the woman and her three-year-old daughter into custody after failing to find her husband, Amnesty International said. The child was released after five days but her mom, a 33-year-old school teacher, was sentenced to life in prison. \"Even by the normally harsh standards of \\'justice\\' meted out by Myanmar\\'s military government, the life sentence given to Ma Khin Khin Leh was extreme,\" the human rights organization said. She was designated one of Amnesty International USA\\'s priority cases. She was released with 18 others \"widely considered to be political prisoners,\" Amnesty International said. Myanmar\\'s military rulers have been widely condemned for their alleged human rights abuses. Pro-democracy leader and Nobel Peace Prize winner Aung San Suu Kyi has been confined in her home for 12 of the past 18 years. Her last house arrest began in 2003 and has been periodically renewed. In October 2007, clashes erupted between pro-democracy demonstrators and government security forces. As many as 110 people are believed to have been killed in that crackdown, including 40 Buddhist monks. The protests were sparked by a huge fuel price increase imposed by the military government, and quickly escalated. Myanmar\\'s military junta said in mid-October that it had detained more than 2,900 people amid the clashes. In September 2008, Amnesty International reported that Myanmar, also called Burma, had released seven dissidents, among them U Win Tin, a journalist and senior official in the opposition National League for Democracy who had been imprisoned for 19 years.'"},"metadata":{}}]},{"cell_type":"code","source":"summaries[2]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:32:06.511205Z","iopub.execute_input":"2023-06-22T11:32:06.511600Z","iopub.status.idle":"2023-06-22T11:32:06.517951Z","shell.execute_reply.started":"2023-06-22T11:32:06.511568Z","shell.execute_reply":"2023-06-22T11:32:06.516821Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"School teacher among 19 political prisoners freed in Myanmar, Amnesty says . Ma Khin Khin Leh sentenced to life in 1999 after her husband planned a protest . Myanmar's military rulers are widely condemned for alleged human rights abuses . Pro-democracy leader Aung San Suu Kyi still confined to home .\""},"metadata":{}}]},{"cell_type":"code","source":"input_ids = tokenizer(paragraph[2], max_length=512, padding=True, truncation=True, return_tensors=\"pt\").input_ids.to(device)\n\ngenerated_ids = models.generate(input_ids)\ngenerated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:36:13.067292Z","iopub.execute_input":"2023-06-22T11:36:13.067646Z","iopub.status.idle":"2023-06-22T11:36:14.121717Z","shell.execute_reply.started":"2023-06-22T11:36:13.067618Z","shell.execute_reply":"2023-06-22T11:36:14.120726Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[\"N.N.C. is the U.N.'s highest-ranking official in charge of peacekeeping operations in the Middle East. It is responsible for peacekeeping efforts in Afghanistan, Iraq, Lebanon and Afghanistan. It's also the highest-ranked country in the world in terms of troop numbers. It has the highest level of peacekeepers in the region.\"]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing Rouge metric for evaluation of testing data","metadata":{}},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:36:21.376594Z","iopub.execute_input":"2023-06-22T11:36:21.377452Z","iopub.status.idle":"2023-06-22T11:36:36.428650Z","shell.execute_reply.started":"2023-06-22T11:36:21.377408Z","shell.execute_reply":"2023-06-22T11:36:36.427422Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=e4bc6746613f42e2f515c84e033bc2283f2bd0d0a359600156dd281ff45077a1\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:31:28.417558Z","iopub.execute_input":"2023-06-22T10:31:28.418212Z","iopub.status.idle":"2023-06-22T10:31:28.985468Z","shell.execute_reply.started":"2023-06-22T10:31:28.418175Z","shell.execute_reply":"2023-06-22T10:31:28.984464Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Generating the summaries on our test in batches because the model was not taking all records at a time because our GPU does not have high storage","metadata":{}},{"cell_type":"code","source":"generated_summaries=[]\ni=0\nj=10\nwhile j <=1000:\n    print(i,j)\n    input_ids = tokenizer(para_test[i:j],padding=True,truncation=True, max_length=512, return_tensors=\"pt\").input_ids.to(device)\n\n    generated_ids = model.generate(input_ids)\n    generated = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n    generated_summaries = generated_summaries + generated\n    \n    i+=10\n    j+=10\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:36:36.431240Z","iopub.execute_input":"2023-06-22T11:36:36.432834Z","iopub.status.idle":"2023-06-22T11:40:53.859459Z","shell.execute_reply.started":"2023-06-22T11:36:36.432791Z","shell.execute_reply":"2023-06-22T11:40:53.858355Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"0 10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"10 20\n20 30\n30 40\n40 50\n50 60\n60 70\n70 80\n80 90\n90 100\n100 110\n110 120\n120 130\n130 140\n140 150\n150 160\n160 170\n170 180\n180 190\n190 200\n200 210\n210 220\n220 230\n230 240\n240 250\n250 260\n260 270\n270 280\n280 290\n290 300\n300 310\n310 320\n320 330\n330 340\n340 350\n350 360\n360 370\n370 380\n380 390\n390 400\n400 410\n410 420\n420 430\n430 440\n440 450\n450 460\n460 470\n470 480\n480 490\n490 500\n500 510\n510 520\n520 530\n530 540\n540 550\n550 560\n560 570\n570 580\n580 590\n590 600\n600 610\n610 620\n620 630\n630 640\n640 650\n650 660\n660 670\n670 680\n680 690\n690 700\n700 710\n710 720\n720 730\n730 740\n740 750\n750 760\n760 770\n770 780\n780 790\n790 800\n800 810\n810 820\n820 830\n830 840\n840 850\n850 860\n860 870\n870 880\n880 890\n890 900\n900 910\n910 920\n920 930\n930 940\n940 950\n950 960\n960 970\n970 980\n980 990\n990 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"len(generated_summaries)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:07.574210Z","iopub.execute_input":"2023-06-22T11:50:07.574653Z","iopub.status.idle":"2023-06-22T11:50:07.581732Z","shell.execute_reply.started":"2023-06-22T11:50:07.574621Z","shell.execute_reply":"2023-06-22T11:50:07.580752Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric\nrouge_metric = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:11.036062Z","iopub.execute_input":"2023-06-22T11:50:11.036438Z","iopub.status.idle":"2023-06-22T11:50:13.026150Z","shell.execute_reply.started":"2023-06-22T11:50:11.036407Z","shell.execute_reply":"2023-06-22T11:50:13.025171Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e54d6db7d004733b54c09284166de87"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_hypotheses = tokenizer.batch_encode_plus(\n    generated_summaries,\n    padding=True,\n    truncation=True,\n    max_length=128,\n    return_tensors=\"pt\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:23.452580Z","iopub.execute_input":"2023-06-22T11:50:23.453656Z","iopub.status.idle":"2023-06-22T11:50:23.688421Z","shell.execute_reply.started":"2023-06-22T11:50:23.453619Z","shell.execute_reply":"2023-06-22T11:50:23.687409Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"tokenized_references = tokenizer.batch_encode_plus(\n    summary_test[:1000],\n    padding=True,\n    truncation=True,\n    max_length=128,\n    return_tensors=\"pt\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:29.226207Z","iopub.execute_input":"2023-06-22T11:50:29.226593Z","iopub.status.idle":"2023-06-22T11:50:29.457651Z","shell.execute_reply.started":"2023-06-22T11:50:29.226561Z","shell.execute_reply":"2023-06-22T11:50:29.456299Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"hypotheses_str = tokenizer.batch_decode(tokenized_hypotheses.input_ids, skip_special_tokens=True)\nreferences_str = tokenizer.batch_decode(tokenized_references.input_ids, skip_special_tokens=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:35.018537Z","iopub.execute_input":"2023-06-22T11:50:35.019286Z","iopub.status.idle":"2023-06-22T11:50:35.141246Z","shell.execute_reply.started":"2023-06-22T11:50:35.019231Z","shell.execute_reply":"2023-06-22T11:50:35.140374Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:03:36.341146Z","iopub.execute_input":"2023-06-22T11:03:36.341556Z","iopub.status.idle":"2023-06-22T11:03:36.963464Z","shell.execute_reply.started":"2023-06-22T11:03:36.341524Z","shell.execute_reply":"2023-06-22T11:03:36.961476Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Calculating the score using ROUGE","metadata":{}},{"cell_type":"code","source":"rouge_results = rouge_metric.compute(predictions=hypotheses_str, references=references_str)\n\n# Access individual ROUGE scores\nrouge1_f1 = rouge_results[\"rouge1\"].mid.fmeasure\nrouge2_f1 = rouge_results[\"rouge2\"].mid.fmeasure\nrougeL_f1 = rouge_results[\"rougeL\"].mid.fmeasure\n\nprint(f\"ROUGE-1 F1 Score: {rouge1_f1:.4f}\")\nprint(f\"ROUGE-2 F1 Score: {rouge2_f1:.4f}\")\nprint(f\"ROUGE-L F1 Score: {rougeL_f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:50:39.366352Z","iopub.execute_input":"2023-06-22T11:50:39.367055Z","iopub.status.idle":"2023-06-22T11:50:42.952957Z","shell.execute_reply.started":"2023-06-22T11:50:39.367019Z","shell.execute_reply":"2023-06-22T11:50:42.951175Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"ROUGE-1 F1 Score: 0.3855\nROUGE-2 F1 Score: 0.1800\nROUGE-L F1 Score: 0.2832\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The model performed pretty decent with average score because I don't have a good computing resources, I couldn't train the model with more data and with more epochs.Still the model performed pretty well","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}